# a typical dockerized deployment setup

## local swarm setup

### pre-installed services
a bunch of services are installed providing useful features to ease development targeting multi-host or cloud environment, such includes monitoring, logging, service registration and discovery, etc.

#### diagram
![infrastructure diagram](/infrastructure-dev-diagram.png?raw=true "Infrastructure diagram")

#### docker registry
a private docker image hub, providing easy access to a handful of frequent used images, or internal docker build artifacts, it is installed on infra vm, opened on port 5000 for http access.
#### consul
a kv store, providing service registration, discovery, DNS service, etc. the master node is installed on infra vm, opened on port 8500 for http access; the agent nodes are installed on every swarm vm, also opened on port 8500 via http.
#### registrator
a tool for monitoring container life cycle activities, providing service registration and de-registration through consul api. it is installed on every swarm vm.
#### prometheus
a visualization tool of system performance metrics, it is installed on monitor vm, opened port 9090 for http access. it is configured to collect performance data from cadvisor's http endpoint.
#### cadvisor
a tool for collecting container/machine level performance metrics, it is installed on every swarm vm, opened port 9090 for http access.
#### ELK log stack
logspout is installed on every swarm vm, to collect running containers stdout/stderr output, and forwards those logs to logstash installed on monitor vm, via syslog://9080; logspout also opens port 9080 via http, to provide individual vm log access.
elasticsearch is installed on monitor vm, it is opened on port 9200 via, mainly to provide log data for kibana to display.
logstash is installed on monitor vm, opened on port 9080 via udp, to accept and parse incoming logs generated by logspout.
kibana is installed on monitor vm, opened on port 9060 via http, to provide log visualization and analyzing aids.

### how to deploy and run the example app
if you haven't, install docker, docker-machine, and make

setup infrastructure vm, which serves as consul master, private docker hub
```shell
make local_infra_create
```
setup docker swarm cluster, 1 master, 2 slave nodes
```shell
make local_swarm_create
```
config local docker client to connect to swarm
```shell
eval "$(docker-machine env --swarm swarm)"
```
build and publish the example app into private docker hub
```shell
cd examples/node_api
make private
```
start example, this step starts a nginx container on swarm master, two nodejs app containers on slave nodes. these containers communicate with each other via an overlay network, only the nginx container exposed port 80 on swarm master. traffics coming in are reversed proxied through this port to one of the two backend node api containers.
```shell
cd ../../
make example_up
```
if everything goes well, you should now be able to access the example via the address produced from previous step, via http://swarm_master_vm_ip:80/

also, when the example app starts, it gets registered automatically into consul running on the infrastructure vm, which you can access via http://infrastructure_vm_ip:8500/ui/#/dc1/services. you should be able to see the example app just deployed listed under the name example-api-80 and in a healthy state.
